include './base'
include './f64'
include './cbqnDefs'
if (hasarch{'AVX2'}) {
  include './sse'
  include './avx'
  include './avx2'
} else if (hasarch{'X86_64'}) {
  include './sse2'
} else if (hasarch{'AARCH64'}) {
  include './neon'
}
include './bitops'
include './mask'

def bitsel{VL, T, r, bits, e0, e1, len} = {
  def bulk = VL/width{T}
  def VT = [bulk]T
  
  e0v:= VT**e0
  e1v:= VT**e1
  @maskedLoop{bulk}(r in tup{'g',r}, b in tup{'b',VT,bits} over i to len) r{homBlend{e0v, e1v, b}}
}

fn bitsel_i{VL,T}(r:*void, bits:*u64, e0:u64, e1:u64, len:u64) : void = {
  bitsel{VL, T, *T~~r, bits, trunc{T,e0}, trunc{T,e1}, len}
}

def table{w} = each{{T} => bitsel_i{w, T}, tup{u8, u16, u32, u64}}

exportT{'simd_bitsel', table{arch_defvw}}