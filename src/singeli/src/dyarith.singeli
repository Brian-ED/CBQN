include './base'
include './f64'
include './cbqnDefs'
include './avx'
include './avx2'
include './bitops'


def rootty{T & match{typekind{T},'primitive'}} = T
def rootty{T & match{typekind{T},'vector'}} = eltype{T}

# TODO more to some more headerlike file
def ty_dbl{T &  i8==T} = i16
def ty_dbl{T & i16==T} = i32
def ty_dbl{T & i32==T} = i64
def ty_dbl{T & isvec{T}} = [vcount{T}/2](ty_dbl{eltype{T}})
def dcast_i{x} = ext{ty_dbl{type{x}}, x}
def to_el{E, x:T} = cast_v{[width{T}/width{E}]E, x}

# get mask of first n items; n>0 & n<vcount{T}
def genmask{T,n & w256{T, 8}} = load{cast_p{[32]i8,  emit{*i8,  '', 'mask8' } + (n^31)}, 0}
def genmask{T,n & w256{T,16}} = load{cast_p{[16]i16, emit{*i16, '', 'mask16'} + (n^15)}, 0}
def genmask{T,n & w256{T,32}} = load{cast_p{[ 8]i32, emit{*i32, '', 'mask32'} + (n^7)}, 0}
def genmask{T,n & w256{T,64}} = load{cast_p{[ 4]i64, emit{*i64, '', 'mask64'} + (n^3)}, 0}

def maskstoreF{p, m, n, x:T & width{eltype{T}}>=32} = maskstore{p,m,n,x}
def maskstoreF{p, m, n, x:T} = store{p, n, blendf{load{p,n}, x, m}}


# + & -
def arithChk1{F, M, w:T, x:T, r:T & match{F,__add}} = anyneg{M{(w^r) & (x^r)}}
def arithChk1{F, M, w:T, x:T, r:T & match{F,__sub}} = anyneg{M{(w^x) & (w^r)}}
def arithChk1{F, M, w:T, x:T, r:T & match{F,__add} & isvec{T} & width{eltype{T}}<=16} = any{M{to_el{i8, __adds{w,x}} != to_el{i8, r}}}
def arithChk1{F, M, w:T, x:T, r:T & match{F,__sub} & isvec{T} & width{eltype{T}}<=16} = any{M{to_el{i8, __subs{w,x}} != to_el{i8, r}}}

def arithChk2{F, M, w:T, x:T, i & issigned{rootty{T}}} = {
  r:= F{w,x}
  tup{r, arithChk1{F, M, w, x, r}}
}

# ×/∧
def arithChk2{F, M, w:T, x:T, i & match{F,__mul} & match{typekind{T},'primitive'}} = {
  r:= F{dcast_i{w}, dcast_i{x}}
  tup{r, r!=ext{type{r}, trunc{T, r}}}
}

def arithChk2{F, M, w:T, x:T, i & match{F,__mul} & isvec{T} & i16==eltype{T}} = {
  rl:= __mul  {w,x}
  rh:= __mulhi{w,x}
  tup{rl, any{M{rh != rl>>15}}}
}
def arithChk2{F, M, w:T, x:T, i & match{F,__mul} & isvec{T} & i8==eltype{T}} = {
  def wp = unpackQ{w, cast_v{T,broadcast{T,0}>w}}
  def xp = unpackQ{x, cast_v{T,broadcast{T,0}>x}}
  def rp = each{__mul, wp, xp}
  def bad = each{{v}=>cast_v{[16]i16,(v<<8)>>8 != v}, rp}
  if (M{0}) { # masked check
    tup{packQ{rp}, any{M{packQ{bad}}}}
  } else { # unmasked check; can do check in a simpler way
    tup{packQ{rp}, any{tupsel{0,bad}|tupsel{1,bad}}}
  }
}
def arithChk2{F, M, w:T, x:T, i & match{F,__mul} & isvec{T} & i32==eltype{T}} = {
  max:= cast_v{[8]f32, broadcast{[8]u32, 0x4efffffe}}
  def cf32{x} = emit{[8]f32, '_mm256_cvtepi32_ps', x}
  f32mul:= cf32{w} * cf32{x}
  tup{w*x, any{M{cast_v{[8]u32, emit{[8]f32, '_mm256_cmp_ps', abs{f32mul}, max, 29}}}}}
  # TODO fallback to the below if the above fails
  # def wp = unpackQ{w, broadcast{T, 0}}
  # def xp = unpackQ{x, broadcast{T, 0}}
  # def rp = each{__mul32, wp, xp}
  # def T2 = ty_dbl{T}
  # def bad = each{{v}=>{
  #   ((cast_v{T2,v} + broadcast{T2,0x80000000}) ^ broadcast{T2, cast{i64,1}<<63}) > broadcast{T2, cast_i{i64, (cast{u64,1}<<63) | 0xFFFFFFFF}}
  # }, rp}
  # tup{packQQ{each{{v} => v&broadcast{T2, 0xFFFFFFFF}, rp}}, any{tupsel{0,bad}|tupsel{1,bad}}} TODO use M
}


# f64
def arithChk3{F, M, w:T, x:T, i} = {
  def r2 = arithChk2{F, M, w, x, i}
  if (rare{tupsel{1,r2}}) return{i}
  tupsel{0,r2}
}

def arithChk3{F, M, w:T, x:T, i & f64==rootty{T}} = F{w,x}

def arithAny{VT, F, W, X, r, len} = {
  def bam = vcount{VT}
  def vv = len/bam
  @forv{VT} (r over i from 0 to vv) r = arithChk3{F, {x}=>x, W{i}, X{i}, i*bam}
  left:= len&(bam-1)
  if (left!=0) {
    m:= genmask{VT, left}
    def mask{x:X} = x&cast_v{X,m}
    def mask{x==0} = 1
    rv:= arithChk3{F, mask, W{vv}, X{vv}, vv*bam}
    maskstoreF{cast_p{VT,r}, m, vv, rv}
  }
  len
}

def arithAA{VT, F, w, x, r, len} = {
  arithAny{VT, F, {i}=>load{cast_p{VT,w}, i}, {i}=>load{cast_p{VT,x}, i}, r, len}
}
def arithAS{VT, F, w, x, r, len} = {
  xv:= broadcast{VT, x}
  arithAny{VT, F, {i}=>load{cast_p{VT,w}, i}, {i}=>xv, r, len}
}
def arithSA{VT, F, w, x, r, len} = {
  wv:= broadcast{VT, w}
  arithAny{VT, F, {i}=>wv, {i}=>load{cast_p{VT,x}, i}, r, len}
}


# cast a guaranteed float to a more specific type; return{0} if not possible
def cast_fB{T, x:(u64) & f64==T} = from_B{f64, x}
def cast_fB{T, x:(u64) & issigned{T} & T<i64} = {
  f:f64 = from_B{f64, x}
  r:T = ftrunc{T, f}
  if (rare{f!=fext{r}}) return{cast{Size,0}}
  r
}

arithAA{F,VT}(w: *u8, x: *u8, r: *u8, len: Size) : Size = { def c{x}=cast_p{eltype{VT}, x}; arithAA{VT, F, c{w}, c{x}, c{r}, len} }
arithAS{F,VT}(w: *u8, x: u64, r: *u8, len: Size) : Size = { def T=eltype{VT}; arithAS{VT, F, cast_p {T, w}, cast_fB{T, x}, cast_p{T, r}, len} }
arithSA{F,VT}(w: u64, x: *u8, r: *u8, len: Size) : Size = { def T=eltype{VT}; arithSA{VT, F, cast_fB{T, w}, cast_p {T, x}, cast_p{T, r}, len} }

'avx2_addAA_i8'  = arithAA{__add,[32]i8 }; 'avx2_addAS_i8'  = arithAS{__add,[32]i8 }; 'avx2_addSA_i8'  = arithSA{__add,[32]i8 }
'avx2_addAA_i16' = arithAA{__add,[16]i16}; 'avx2_addAS_i16' = arithAS{__add,[16]i16}; 'avx2_addSA_i16' = arithSA{__add,[16]i16}
'avx2_addAA_i32' = arithAA{__add,[ 8]i32}; 'avx2_addAS_i32' = arithAS{__add,[ 8]i32}; 'avx2_addSA_i32' = arithSA{__add,[ 8]i32}
'avx2_addAA_f64' = arithAA{__add,[ 4]f64}; 'avx2_addAS_f64' = arithAS{__add,[ 4]f64}; 'avx2_addSA_f64' = arithSA{__add,[ 4]f64}
'avx2_subAA_i8'  = arithAA{__sub,[32]i8 }; 'avx2_subAS_i8'  = arithAS{__sub,[32]i8 }; 'avx2_subSA_i8'  = arithSA{__sub,[32]i8 }
'avx2_subAA_i16' = arithAA{__sub,[16]i16}; 'avx2_subAS_i16' = arithAS{__sub,[16]i16}; 'avx2_subSA_i16' = arithSA{__sub,[16]i16}
'avx2_subAA_i32' = arithAA{__sub,[ 8]i32}; 'avx2_subAS_i32' = arithAS{__sub,[ 8]i32}; 'avx2_subSA_i32' = arithSA{__sub,[ 8]i32}
'avx2_subAA_f64' = arithAA{__sub,[ 4]f64}; 'avx2_subAS_f64' = arithAS{__sub,[ 4]f64}; 'avx2_subSA_f64' = arithSA{__sub,[ 4]f64}
'avx2_mulAA_i8'  = arithAA{__mul,[32]i8 }; 'avx2_mulAS_i8'  = arithAS{__mul,[32]i8 }; 'avx2_mulSA_i8'  = arithSA{__mul,[32]i8 }
'avx2_mulAA_i16' = arithAA{__mul,[16]i16}; 'avx2_mulAS_i16' = arithAS{__mul,[16]i16}; 'avx2_mulSA_i16' = arithSA{__mul,[16]i16}
'avx2_mulAA_i32' = arithAA{__mul,[ 8]i32}; 'avx2_mulAS_i32' = arithAS{__mul,[ 8]i32}; 'avx2_mulSA_i32' = arithSA{__mul,[ 8]i32}
'avx2_mulAA_f64' = arithAA{__mul,[ 4]f64}; 'avx2_mulAS_f64' = arithAS{__mul,[ 4]f64}; 'avx2_mulSA_f64' = arithSA{__mul,[ 4]f64}