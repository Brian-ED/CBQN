local def maskInit1{w} = {
  apply{merge, each{{x} => {
    merge{(w/8-1)**255, (1<<x)-1, (w/8)**0}
  }, iota{8}}}
}
mask256_1:*u8 = maskInit1{256}; def maskOfBit{T,n if width{T}==256} = load{*[32]u8  ~~  (mask256_1 + (n>>3)^31 + 64*(n&7))}
mask128_1:*u8 = maskInit1{128}; def maskOfBit{T,n if width{T}==128} = load{*[16]u8  ~~  (mask128_1 + (n>>3)^15 + 32*(n&7))}

mask256:*i64 = merge{4 ** -1,  4 ** 0}
local def maskOfImpl{T, n, w} = load{*ty_u{T} ~~ (*u8~~mask256 + 32 - n*(elwidth{T}/8))}

# get homogeneous mask of first n items; 0 ≤ n ≤ vcount{T}
def maskOf{T,n if w256{T}} = maskOfImpl{T, n, 256}
def maskOf{T,n if w128{T}} = maskOfImpl{T, n, 128}
def maskOf{T,n if  w64{T}} = maskOfImpl{T, n,  64}

def anyne{x:T, y:T, M if M{0}==0 and isvec{T}} = ~homAll{x==y}
def anyne{x:T, y:T, M if M{0}==1 and isvec{T}} =  homAny{M{x!=y}}
def anyne{x:T, y:T, M if M{0}==0 and anyInt{x}} = x!=y
def anyne{x:T, y:T, M if M{0}==1 and anyInt{x}} = M{x^y} != 0
def anyneBit{x:T, y:T, M} = ~M{x^y, 'all bits zeroes'}

def anynePositive{x:T, y:T, M if M{0}==0} = anyne{x, y, M}
def anynePositive{x:T, y:T, M if M{0}==1 and isvec{T}} = {
  def {n,m} = homMaskX{x==y}
  def E = tern{type{m}==u64, u64, u32}
  (promote{E,~m} << (width{E}-M{'count'}*n)) != 0
}

def maskNone{x} = x
def maskNone{x, ('all bits zeroes')} = andAllZero{x, x}
def maskAfter{n} = {
  def mask{x:X, ('all bits zeroes')} = andAllZero{x, X~~maskOfBit{X,n}}
  def mask{X, ('to sign bits')} = maskOf{X,n}
  def mask{X, ('to homogeneous bits')} = maskOf{X,n}
  def mask{('count')} = n
  def mask{{x}} = tup{mask{x}}
  def mask{x:X if isvec{X}} = x & (X~~maskOf{X,n})
  def mask{x:X if anyInt{x}} = x & ((1<<n) - 1)
  def mask{(0)} = 1
}



def loadLowBatch{T, ptr:P, w, n if eltype{P}==eltype{T}} = loadLow{*T ~~ (ptr + n*(w/elwidth{P})), w}

# store vcount{T} items into the n'th batch of ptr elements, compressing the items if needed; masked by M
def storeBatch{ptr:P, n, x:T, M} = {
  def rpos = ptr + n*vcount{T}
  def E0 = eltype{P}
  def TF = re_el{E0, T}
  xu:= narrow{E0, x}
  
  if (M{0}) homMaskStoreF{*TF~~rpos, M{TF, 'to homogeneous bits'}, undefPromote{TF, xu}}
  else storeLow{rpos, vcount{T}*width{E0}, xu}
}

# (sign/zero)-extend n'th batch of vcount{T} elements of P into elements of T
def loadBatch{ptr:P, n, T} = {
  def rpos = ptr + n*vcount{T}
  def E0 = eltype{P}
  
  widen{T, loadLow{*re_el{E0, T} ~~ rpos, vcount{T}*width{E0}}}
}

def loadBatch {ptr:P, ns, T     if istup{ns}} = each{{n  } => loadBatch {ptr, n, T   }, ns}
def storeBatch{ptr:P, ns, xs, M if istup{ns}} = each{{n,x} => storeBatch{ptr, n, x, M}, ns, xs}



# "harmless" pointer cast that'll only cast void*
def hCast{T,p} = assert{0, 'expected pointer with element',T,'or void but got ',p}
def hCast{T,p:*T} = p
def hCast{T,p:(*void)} = *T~~p

def mlExec{i, iter, vars0, bulk, M} = {
  def vproc{p:P if isptr{P}} = p
  def vproc{('m')} = tptr{{_}=>M, '!'}
  
  def vproc{{T,p:P}} = tptr{{i} => loadBatch{p, i, T}, {i,x} => storeBatch{p, i, x, M}}
  def vproc{{('b'),  p:P}} = tptr{{i} => b_getBatch{bulk, hCast{u64,p}, i}, '!'}
  def vproc{{('b'),T,p:P}} = tptr{{i} => loadBatchBit{T, hCast{u64,p}, i}, '!'}
  def vproc{{('g'),  p:P}} = tptr{{i} => ({x} => storeBatch{p, i, x, M}), '!'}
  def vproc{{('g'),T,p:P}} = tptr{{i} => {
    def dv{} = loadBatch{p, i, T}
    def dv{x} = storeBatch{p, i, x, M}
  }, '!'}
  
  iter{i, each{vproc, vars0}}
}

# i0 - initial batch index; not used as begin because it's in a different scale compared to end
def maskedLoop{bulk, i0}{vars,begin==0,end,iter} = {
  l:u64 = end
  
  m:u64 = l / bulk
  @for (i from i0 to m) mlExec{i, iter, vars, bulk, maskNone}
  
  left:= l & (bulk-1)
  if (left!=0) mlExec{m, iter, vars, bulk, maskAfter{left}}
}
def maskedLoop{bulk} = maskedLoop{bulk,0}


def maskedLoopPositive{bulk}{vars,begin==0,end:L,iter} = {
  assert{end > 0}
  i:L = 0
  while(i < (end-1)/bulk) {
    mlExec{i, iter, vars, bulk, maskNone}
    ++i
  }
  mlExec{i, iter, vars, bulk, maskAfter{end - i*bulk}}
}



# masked unrolled loop
#  bulk: vector count
#  unr: unroll amount
#  fromunr (optional): {}=>{transition from unrolled to non-unrolled}
#  loop args:
#    begin must be 0
#    end is scalar element count
#    index given is a tuple of batch indexes to process
def muLoop{bulk, unr, fromunr}{vars,begin==0,end,iter} = {
  l:u64 = end
  
  m:u64 = l / bulk
  if (unr==1) {
    @for (i from 0 to m) mlExec{tup{i}, iter, vars, bulk, maskNone}
    
    left:= l & (bulk-1)
    if (left!=0) mlExec{tup{m}, iter, vars, bulk, maskAfter{left}}
  } else {
    if (m > 0) {
      i:u64 = 0
      if (unr <= m) {
        while ((i+unr) <= m) {
          def is = each{{j}=>i+j, iota{unr}}
          mlExec{each{{j}=>i+j, iota{unr}}, iter, vars, bulk, maskNone}
          i+= unr
        }
        fromunr{}
      }
      if (unr==2) {
        if (i!=m) mlExec{tup{i}, iter, vars, bulk, maskNone}
      } else {
        @for(j from i to m) mlExec{tup{j}, iter, vars, bulk, maskNone}
      }
    }
    
    left:= l & (bulk-1)
    if (left!=0) mlExec{tup{m}, iter, vars, bulk, maskAfter{left}}
  }
}
def muLoop{bulk, unr} = muLoop{bulk, unr, {}=>0}
