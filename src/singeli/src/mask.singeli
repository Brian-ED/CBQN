local def maskInit1{w} = {
  apply{merge, each{{x} => {
    merge{(w/8-1)**255, (1<<x)-1, (w/8)**0}
  }, iota{8}}}
}
mask256_1:*u8 = maskInit1{256}; def maskOfBit{T,n & width{T}==256} = load{*[32]u8  ~~  (mask256_1 + (n>>3)^31 + 64*(n&7))}
mask128_1:*u8 = maskInit1{128}; def maskOfBit{T,n & width{T}==128} = load{*[16]u8  ~~  (mask128_1 + (n>>3)^15 + 32*(n&7))}

mask256:*i64 = merge{4 ** -1,  4 ** 0}
local def maskOfImpl{T, n, w} = load{*ty_u{T} ~~ (*u8~~mask256 + 32 - n*(elwidth{T}/8))}

# get homogeneous mask of first n items; 0 ≤ n ≤ vcount{T}
def maskOf{T,n & width{T}==256} = maskOfImpl{T, n, 256}
def maskOf{T,n & width{T}==128} = maskOfImpl{T, n, 128}
def maskOf{T,n & width{T}== 64} = maskOfImpl{T, n,  64}

def anyne{x:T, y:T, M & M{0}==0 & isvec{T}} = ~homAll{x==y}
def anyne{x:T, y:T, M & M{0}==1 & isvec{T}} =  homAny{M{x!=y}}
def anyne{x:T, y:T, M & M{0}==0 & anyInt{x}} = x!=y
def anyne{x:T, y:T, M & M{0}==1 & anyInt{x}} = M{x^y} != 0
def anyneBit{x:T, y:T, M} = ~M{x^y, 'all bits zeroes'}

def anynePositive{x:T, y:T, M & M{0}==0} = anyne{x, y, M}
def anynePositive{x:T, y:T, M & M{0}==1 & isvec{T}} = {
  def {n,m} = homMaskX{x==y}
  def E = tern{type{m}==u64, u64, u32}
  (promote{E,~m} << (width{E}-M{'count'}*n)) != 0
}

def maskNone{x} = x
def maskNone{x, mode=='all bits zeroes'} = andAllZero{x, x}
def maskAfter{n} = {
  def mask{x:X & isvec{X}} = x & (X~~maskOf{X,n})
  def mask{x:X & anyInt{x}} = x & ((1<<n) - 1)
  def mask{x:X, mode=='all bits zeroes'} = andAllZero{x, X~~maskOfBit{X,n}}
  def mask{X, mode=='to sign bits'} = maskOf{X,n}
  def mask{X, mode=='to homogeneous bits'} = maskOf{X,n}
  def mask{mode=='count'} = n
  def mask{x & istup{x} & tuplen{x}==1} = tup{mask{tupsel{0,x}}}
  def mask{x==0} = 1
}



def loadLowBatch{T, ptr:P, w, n & eltype{P}==eltype{T}} = loadLow{*T ~~ (ptr + n*(w/elwidth{P})), w}

# store vcount{T} items into the n'th batch of ptr elements, compressing the items if needed; masked by M
def storeBatch{ptr:P, n, x:T, M} = {
  def rpos = ptr + n*vcount{T}
  def E0 = eltype{P}
  def TF = to_el{E0, T}
  xu:= narrow{E0, x}
  
  if (M{0}) homMaskStoreF{*TF~~rpos, M{TF, 'to homogeneous bits'}, undefPromote{TF, xu}}
  else storeLow{rpos, vcount{T}*width{E0}, xu}
}

# (sign/zero)-extend n'th batch of vcount{T} elements of P into elements of T
def loadBatch{ptr:P, n, T} = {
  def rpos = ptr + n*vcount{T}
  def E0 = eltype{P}
  
  widen{T, loadLow{*to_el{E0, T} ~~ rpos, vcount{T}*width{E0}}}
}

def loadBatch {ptr:P, ns, T     & istup{ns}} = each{{n  } => loadBatch {ptr, n, T   }, ns}
def storeBatch{ptr:P, ns, xs, M & istup{ns}} = each{{n,x} => storeBatch{ptr, n, x, M}, ns, xs}



def maskedLoopPositive{bulk, l:L, step} = {
  i:L = 0
  while(i < (l-1)/bulk) {
    step{i, maskNone}
    ++i
  }
  step{i, maskAfter{l - i*bulk}}
}


# "harmless" pointer cast that'll only cast void*
def hCast{T,p} = assert{show{'expected pointer with element',T,'or void but got ',p}}
def hCast{T,p:P & match{T,eltype{P}}} = p
def hCast{T,p:P & match{P,*void}} = *T~~p

# masked loop arguments
#  p:*T - regular pointer, loaded by the batch index(es)
#  tup{VT,p:*T} - loadBatch/storeBatch vector data
#  tup{'b',p:P} - b_getBatch
#  tup{'b',VT,p:P} - loadBatchBit
#  tup{'g',VT,p:*T} - gives a generator supporting g{} for loadBatch and g{newValue} for storeBatch
#  tup{'g',p:*T} - the above, but without load support
def mlExec{i, block, vars0, bulk, M} = {
  def vproc2{T,p:P} = tptr{{i} => loadBatch{p, i, T}, {i,x} => storeBatch{p, i, x, M}}
  def vproc2{S=='b',  p:P} = tptr{{i} => b_getBatch{bulk, hCast{u64,p}, i}, '!'}
  def vproc2{S=='b',T,p:P} = tptr{{i} => loadBatchBit{T, hCast{u64,p}, i}, '!'}
  def vproc2{S=='g',  p:P} = tptr{{i} => ({x} => storeBatch{p, i, x, M}), '!'}
  def vproc2{S=='g',T,p:P} = tptr{{i} => {
    def dv{} = loadBatch{p, i, T}
    def dv{x} = storeBatch{p, i, x, M}
  }, '!'}
  
  def vproc{p:P & isptr{P}} = p
  def vproc{S=='m'} = tptr{{_}=>M, '!'}
  def vproc{t & ktup{t}} = vproc2{...t}
  
  block{i, each{vproc, vars0}}
}

# i0 - initial batch index; not used as begin because it's in a different scale compared to end
def maskedLoop{bulk, i0}{vars,begin==0,end,block} = {
  l:u64 = end
  
  m:u64 = l / bulk
  @for (i from i0 to m) mlExec{i, block, vars, bulk, maskNone}
  
  left:= l & (bulk-1)
  if (left!=0) mlExec{m, block, vars, bulk, maskAfter{left}}
}
def maskedLoop{bulk} = maskedLoop{bulk,0}



# masked unrolled loop
#  bulk: vector count
#  unr: unroll amount
#  fromunr (optional): {}=>{transition from unrolled to non-unrolled}
#  loop args:
#    begin must be 0
#    end is scalar element count
#    index given is a tuple of batch indexes to process
def muLoop{bulk, unr, fromunr}{vars,begin==0,end,block} = {
  l:u64 = end
  def step = 123123123
  
  m:u64 = l / bulk
  if (unr==1) {
    @for (i from 0 to m) mlExec{tup{i}, block, vars, bulk, maskNone}
    
    left:= l & (bulk-1)
    if (left!=0) mlExec{tup{m}, block, vars, bulk, maskAfter{left}}
  } else {
    if (m > 0) {
      i:u64 = 0
      if (unr <= m) {
        while ((i+unr) <= m) {
          def is = each{{j}=>i+j, iota{unr}}
          mlExec{each{{j}=>i+j, iota{unr}}, block, vars, bulk, maskNone}
          i+= unr
        }
        fromunr{}
      }
      if (unr==2) {
        if (i!=m) mlExec{tup{i}, block, vars, bulk, maskNone}
      } else {
        @for(j from i to m) mlExec{tup{j}, block, vars, bulk, maskNone}
      }
    }
    
    left:= l & (bulk-1)
    if (left!=0) mlExec{tup{m}, block, vars, bulk, maskAfter{left}}
  }
}
def muLoop{bulk, unr} = muLoop{bulk, unr, {}=>0}
