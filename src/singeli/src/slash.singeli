include './base'
include './bmi2'

def storeu{p:T, i, v:eltype{T} & *u64==T} = emit{void, 'storeu_u64', p+i, v}
def loadu{p:T & *u64==T} = emit{eltype{T}, 'loadu_u64', p}

def comp8{w:*u64, X, r:*i8, l:u64} = {
  @for(w in *u8~~w over i to cdiv{l,8}) {
    pc:= popc{w}
    storeu{*u64~~r, 0, pext{promote{u64,X{}}, pdep{promote{u64, w}, cast{u64,0x0101010101010101}}*255}}
    r+= pc
  }
}

def tab{n,l} = {
  def m=n-1; def t=tab{m,l}
  def k = (1<<l - 1) << (m*l)
  merge{t, k+t}
}
def tab{n==0,l} = tup{0}
c16lut:*u64 = tab{4,16}

def vgLoad{p:T, i & T == *u64} = emit{eltype{T}, 'vg_load64', p, i}

def comp16{w:*u64, X, r:*i16, l:u64} = {
  @for(w in *u8~~w over i to cdiv{l,8}) {
    def step{w} = {
      pc:= popcRand{w}
      storeu{*u64~~r, 0, pext{promote{u64,X{}}, vgLoad{c16lut, w}}}
      r+= pc
    }
    step{w&15}
    step{w>>4} # this runs even if the above step was all that's required, so it'll act on the invalid result of "r+= pc", so we need to overallocate even more to compensate
  }
}

slash2{F, T}(w:*u64, x:*T, r:*T, l:u64) : void = {
  xv:= *u64~~x
  F{w, {} => {c:= loadu{xv}; xv+= 1; c}, r, l}
}

slash1{F, T, iota, add}(w:*u64, r:*T, l:u64) : void = {
  x:u64 = iota
  F{w, {} => {c:= x; x+= add; c}, r, l}
}

# 8-bit writes ~8 bytes of garbage past end, 16-bit writes ~16 bytes
'bmipopc_2slash8' = slash2{comp8, i8}
'bmipopc_2slash16' = slash2{comp16, i16}
'bmipopc_1slash8' = slash1{comp8, i8, 0x0706050403020100, 0x0808080808080808}
'bmipopc_1slash16' = slash1{comp16, i16, 0x0003000200010000, 0x0004000400040004}

include './sse3'
include './avx'
include './avx2'
include './mask'
include 'util/tup'
def incl{a,b} = slice{iota{b+1},a}

# 1+˝∨`⌾⌽0=div|⌜range
def makefact{divisor, range} = {
  def t = table{{a,b}=>0==b%a, divisor, range}
  fold{+, 1, reverse{scan{|, reverse{t}}}}
}
def basic_rep = incl{2,7}
def fact_size = 128
def fact_inds = slice{iota{fact_size},8}
def fact_tab = makefact{basic_rep, fact_inds}
factors:*u8 = fact_tab

def get_shufs{step, wv, len} = {
  def i = iota{len*step}
  split{step, (i - i%wv)/wv}
}
def get_shuf_data{wv, elbytes, len} = {
  def expand{ex}{s} = join{table{+, ex*s, iota{ex}}}
  def expand{ex==1}{s} = s
  each{expand{elbytes}, get_shufs{32 / elbytes, wv, len}}
}
def get_shuf_data{wv, b} = get_shuf_data{wv, b, wv}
def rep_iter_from_sh{sh} = {
  def l = tuplen{sh}
  def h = l >> 1
  {x, gen} => {
    def fs{v, s} = gen{sel{[16]i8, v, s}}
    a := shuf{[4]u64, x, 4b1010}; each{bind{fs,a}, slice{sh,0,h}}
    if (l%2) fs{x, tupsel{h, sh}}
    b := shuf{[4]u64, x, 4b3232}; each{bind{fs,b}, slice{sh,-h}}
  }
}
def get_rep_iter{V, wv==2}{x, gen} = {
  def s = shuf{[4]u64, x, 4b3120}
  each{{q}=>gen{V~~q}, unpackQ{s, s}}
}
def get_rep_iter{V==[4]u64, wv} = {
  def step = 4
  def base4{l} = { if (0==tuplen{l}) 0; else tupsel{0,l}+4*base4{slice{l,1}} }
  def sh = each{base4, get_shufs{step, wv, wv}}
  {x, gen} => each{{s}=>gen{shuf{V, x, s}}, sh}
}
def rep_const_shuffle{V, wv, onreps, xv:*V, rv:*V, n:u64} = {
  def step = vcount{V}
  nv := n / step
  j:u64 = 0
  def write{v} = { store{rv, j, v}; ++j }
  @for (xv over nv) onreps{xv, write}
  if (nv*step < n) {
    nr := n * wv
    e := nr / step
    s := broadcast{V, 0}
    def end = makelabel{}
    onreps{load{xv,nv}, {v} => {
      s = v
      if (j == e) goto{end}
      write{s}
    }}
    setlabel{end}
    q := nr & (step-1)
    if (q) maskstoreF{rv, maskOf{V, q}, e, s}
  }
}
def rep_const_shuffle{V, wv, xv:*V, rv:*V, n:u64} = rep_const_shuffle{V, wv, get_rep_iter{V, wv}, xv, rv, n}

def rcsh_vals = incl{3, 7}
rcsh_offs:*u8 = shiftright{0, scan{+,rcsh_vals}}
def rcsh_table = table{get_shuf_data, rcsh_vals, tup{1,2,4}}
rcsh_data:*i8 = join{join{join{rcsh_table}}}
rcsh_sub{wv}(x:*i8, r:*i8, n:u64, sh:*[32]i8) : void = {
  def V = [32]i8
  def st = each{bind{load,sh}, iota{wv}}
  rep_const_shuffle{V, wv, rep_iter_from_sh{st}, *V~~x, *V~~r, n}
}
rep_const_shuffle_full(wv:i32, x:*i8, r:*i8, n:u64, sh:*[32]i8) : void = {
  def try{k} = { if (wv==k) rcsh_sub{k}(x, r, n, sh) }
  each{try, rcsh_vals}
}

def rcsh4_dom = replicate{bind{>=,64}, replicate{fact_tab==1, fact_inds}}
rcsh4_dat:*i8 = join{join{each{{wv}=>get_shuf_data{wv, 1, 4}, rcsh4_dom}}}
rchs4_lkup:*i8 = shiftright{0, scan{+, fold{|, table{==, rcsh4_dom, iota{64}}}}}
rep_const_shuffle_partial4(wv:u64, elbytes:u64, x:*i8, r:*i8, n:u64) : void = {
  shp := *[32]i8~~rcsh4_dat + 4*load{rchs4_lkup,wv}
  def double{x} = { s:=shuf{[4]u64, x, 4b3120}; s+=s; each{bind{~~,[32]i8},unpackQ{s, s+broadcast{type{s},1}}} }
  sh0 := load{shp, 0}; sh1:=sh0; sh2:=sh0; sh3:=sh0
  if (elbytes<=2) sh1=load{shp,1}; else tup{sh0,sh1}=double{sh0};
  if (elbytes<=1) tup{sh2,sh3}=each{bind{load,shp},tup{2,3}};
  else { t:=sh1; tup{sh0,sh1}=double{sh0}; tup{sh2,sh3}=double{t} }
  def h = 4; def sh = tup{sh0,sh1,sh2,sh3}
  def V = [32]i8
  def step = vcount{V}     # Bytes written
  def wvb = wv * elbytes
  def hs = (h*step) / wvb  # Actual step size in argument elements
  re := r + n*wvb - h*step
  i:u64 = 0
  while (r <= re) {
    a := shuf{[4]u64, load{*V~~(x+i),0}, 4b1010}
    @unroll (j to h) store{*V~~r, j, sel{[16]i8, a, tupsel{j,sh}}}
    i += hs*elbytes
    r += hs*wvb
  }
  re += (h-1)*step
  a := shuf{[4]u64, load{*V~~(x+i),0}, 4b1010}
  s := broadcast{V, 0}
  def end = makelabel{}
  @unroll (j to h) {
    s = sel{[16]i8, a, tupsel{j,sh}}
    if (r > re) goto{end}
    store{*V~~r, 0, s}
    r += step
  }
  setlabel{end}
  q := (re+step) - r
  if (q) maskstoreF{*V~~r, maskOf{V, q}, 0, s}
}

rep_const_broadcast{T, V, kv}(wv:u64, x:*T, r:*T, n:u64) : void = {
  @for (x over n) {
    v := broadcast{V, x}
    @unroll (j to kv) store{*V~~r, j, v}
    r += wv
    store{*V~~r, -1, v}
  }
}
rep_const_broadcast{T, V, kv==0}(wv:u64, x:*T, r:*T, n:u64) : void = {
  @for (x over n-1) {
    store{*V~~r, 0, broadcast{V, x}}
    r += wv
  }
  maskstoreF{*V~~r, maskOf{V, wv}, 0, broadcast{V, load{x,n-1}}}
}
rep_const_broadcast{T, V}(kv:u64, wv:u64, x:*T, r:*T, n:u64) : void = {
  @for (x over n) {
    v := broadcast{V, x}
    @for (j to kv) store{*V~~r, j, v}
    r += wv
    store{*V~~r, -1, v}
  }
}

rep_const{T}(wv:i32, x:*void, r:*void, n:u64) : void = {
  assert{wv>=2}
  if (wv>=8 and wv<=fact_size) {
    k := u32~~wv
    fa := promote{u32, load{factors,k-8}}
    if (fa > 1) {
      fi := promote{u64, k / fa}
      def t = *T~~r + (promote{u64,k}-fi)*n
      rep_const{T}(fi,x,t,n)
      rep_const{T}(fa,t,r,fi*n)
      return{}
    }
  }
  def wT = width{T}
  def vn = 256/wT
  def V = [vn]T
  def max_shuffle = 2*vn
  if (wv <= max_shuffle) {
    def specialize{k} = {
      if (wv==k) return{rep_const_shuffle{V, k, *V~~x, *V~~r, n}}
    }
    if (wT<=32) {
      def elbytes = wT/8
      specialize{2}
      if (wv <= tupsel{-1,rcsh_vals}) {
        ri := wv - tupsel{0,rcsh_vals}
        def ti = elbytes-1 - (elbytes==4)
        shp:= *[32]i8~~rcsh_data + load{rcsh_offs,ri}*3 + ti*wv
        rep_const_shuffle_full(wv, x, r, n*elbytes, shp)
      } else {
        rep_const_shuffle_partial4(wv, elbytes, x, r, n)
      }
    } else {
      assert{max_shuffle <= tupsel{0, fact_inds}}
      each{specialize, basic_rep}
    }
  } else {
    kv := wv / vn
    @unroll (k from (max_shuffle/vn) to 4) {
      if (kv == k) return{rep_const_broadcast{T, V, k}(wv, x, r, n)}
    }
    rep_const_broadcast{T, V}(kv, wv, x, r, n)
  }
}

'rep_u8'  = rep_const{i8 }; 'rep_u16' = rep_const{i16}
'rep_u32' = rep_const{i32}; 'rep_u64' = rep_const{u64}
